{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RehamHatem/Mobile-Price-Classification/blob/main/Mobile_Price_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpsevbtQq0dQ",
        "outputId": "bab89b24-7f19-4686-c67d-c44d87b32d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n",
            "Train Data Length: 2000\n",
            "Test Data Length: 1000\n",
            "Train Data:\n",
            "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
            "0            842     0          2.2         0   1       0           7    0.6   \n",
            "1           1021     1          0.5         1   0       1          53    0.7   \n",
            "2            563     1          0.5         1   2       1          41    0.9   \n",
            "3            615     1          2.5         0   0       0          10    0.8   \n",
            "4           1821     1          1.2         0  13       1          44    0.6   \n",
            "\n",
            "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
            "0        188        2  ...         20       756  2549     9     7         19   \n",
            "1        136        3  ...        905      1988  2631    17     3          7   \n",
            "2        145        5  ...       1263      1716  2603    11     2          9   \n",
            "3        131        6  ...       1216      1786  2769    16     8         11   \n",
            "4        141        2  ...       1208      1212  1411     8     2         15   \n",
            "\n",
            "   three_g  touch_screen  wifi  price_range  \n",
            "0        0             0     1            1  \n",
            "1        1             1     0            2  \n",
            "2        1             1     0            2  \n",
            "3        1             0     0            2  \n",
            "4        1             1     0            1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Test Data:\n",
            "   id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "0   1           1043     1          1.8         1  14       0           5   \n",
            "1   2            841     1          0.5         1   4       1          61   \n",
            "2   3           1807     1          2.8         0   1       0          27   \n",
            "3   4           1546     0          0.5         1  18       1          25   \n",
            "4   5           1434     0          1.4         0  11       1          49   \n",
            "\n",
            "   m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "0    0.1        193  ...  16        226      1412  3476    12     7   \n",
            "1    0.8        191  ...  12        746       857  3895     6     0   \n",
            "2    0.9        186  ...   4       1270      1366  2396    17    10   \n",
            "3    0.5         96  ...  20        295      1752  3893    10     0   \n",
            "4    0.5        108  ...  18        749       810  1773    15     8   \n",
            "\n",
            "   talk_time  three_g  touch_screen  wifi  \n",
            "0          2        0             1     0  \n",
            "1          7        1             0     0  \n",
            "2         10        0             1     1  \n",
            "3          7        1             1     0  \n",
            "4          7        1             0     1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Unique values in y_train: [1 2 3 0]\n"
          ]
        }
      ],
      "source": [
        "!python setup.py build_ext --inplace\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('/content/train.csv', encoding='latin-1')\n",
        "test_data = pd.read_csv('/content/test.csv', encoding='latin-1')\n",
        "\n",
        "# lengths of train and test data\n",
        "print(\"Train Data Length:\", len(train_data))\n",
        "print(\"Test Data Length:\", len(test_data))\n",
        "\n",
        "# samples of train and test data\n",
        "print(\"Train Data:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())\n",
        "\n",
        "# Split train data into features and target variable\n",
        "X_train = train_data.drop('price_range', axis=1)\n",
        "y_train = train_data['price_range']\n",
        "\n",
        "# Split test data into features\n",
        "X_test = test_data.drop('id', axis=1)  # 'id' column is not a feature\n",
        "test_id = test_data['id']  # Save test IDs\n",
        "\n",
        "# Check and map y_train to proper format\n",
        "print(\"Unique values in y_train:\", pd.unique(y_train))\n",
        "mapping = {0: 0, 1: 1, 2: 1, 3: 0}\n",
        "y_train_mapped = y_train.map(mapping).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_WTNf93UKP"
      },
      "source": [
        "Particle Swarm Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7zxHhBupT2jt"
      },
      "outputs": [],
      "source": [
        "# PSO Parameters\n",
        "num_particles = 20\n",
        "max_iter = 100\n",
        "w = 0.5  # Inertia weight\n",
        "c1 = 2   # Cognitive weight\n",
        "c2 = 2   # Social weight\n",
        "\n",
        "#initialize particles\n",
        "def initialize_particles(num_particles, num_features):\n",
        "    return np.random.choice([0, 1], size=(num_particles, num_features))\n",
        "\n",
        "# evaluate fitness (accuracy) of a particle\n",
        "def fitness(particle, X_train, y_train_mapped):\n",
        "    selected_features = X_train.columns[particle == 1]\n",
        "    if selected_features.empty:\n",
        "        return 0  # Return 0 fitness if no features are selected\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    # Train Decision Tree classifier and calculate accuracy\n",
        "    dt_classifier = CustomDecisionTreeClassifier()\n",
        "    dt_classifier.fit(X_train_selected.values, y_train_mapped)\n",
        "    accuracy = dt_classifier.score(X_train_selected.values, y_train_mapped)\n",
        "    return accuracy\n",
        "\n",
        "# update particle velocity and position\n",
        "def update_particle(particle, velocity, best_particle, global_best_particle):\n",
        "    r1, r2 = np.random.random(size=2)\n",
        "    velocity = w * velocity + c1 * r1 * (best_particle - particle) + c2 * r2 * (global_best_particle - particle)\n",
        "    particle = np.where(np.random.random(len(particle)) < 1 / (1 + np.exp(-velocity)), 1, 0)\n",
        "    return particle, velocity\n",
        "\n",
        "# perform PSO feature selection\n",
        "def pso_feature_selection(X_train, y_train_mapped, X_test):\n",
        "    num_features = X_train.shape[1]\n",
        "    particles = initialize_particles(num_particles, num_features)\n",
        "    velocity = np.zeros((num_particles, num_features))\n",
        "    global_best_particle = particles[0]\n",
        "    global_best_fitness = fitness(global_best_particle, X_train, y_train_mapped)\n",
        "    best_particles = particles.copy()\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        for i, particle in enumerate(particles):\n",
        "            particle_fitness = fitness(particle, X_train, y_train_mapped)\n",
        "            if particle_fitness > global_best_fitness:\n",
        "                global_best_fitness = particle_fitness\n",
        "                global_best_particle = particle.copy()\n",
        "            if particle_fitness > fitness(best_particles[i], X_train, y_train_mapped):\n",
        "                best_particles[i] = particle.copy()\n",
        "        for i, particle in enumerate(particles):\n",
        "            particles[i], velocity[i] = update_particle(particle, velocity[i], best_particles[i], global_best_particle)\n",
        "\n",
        "    selected_features = X_train.columns[global_best_particle == 1]\n",
        "    X_test_selected = X_test[selected_features]\n",
        "    return selected_features, X_test_selected\n",
        "\n",
        "# Call PSO feature selection function for both training and test data\n",
        "selected_features_train, X_test_selected = pso_feature_selection(X_train, y_train_mapped, X_test)\n",
        "\n",
        "# Convert the DataFrame to NumPy arrays for processing with our Decision Tree classifier\n",
        "X_train_selected = X_train[selected_features_train].values.astype(float)\n",
        "X_test_selected = X_test_selected.values.astype(float)\n",
        "y_train = y_train_mapped.values.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print selected feature names and indices for training data\n",
        "print(\"Selected Features for Training Data:\")\n",
        "for index, feature_name in enumerate(selected_features_train):\n",
        "    feature_index = X_train.columns.get_loc(feature_name)\n",
        "    print(\"Index:\", feature_index, \"Feature:\", feature_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyCDHNEKBeB_",
        "outputId": "47e17e4b-bcf6-4587-8bd1-5b96bbb24b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features for Training Data:\n",
            "Index: 3 Feature: dual_sim\n",
            "Index: 4 Feature: fc\n",
            "Index: 6 Feature: int_memory\n",
            "Index: 7 Feature: m_dep\n",
            "Index: 11 Feature: px_height\n",
            "Index: 12 Feature: px_width\n",
            "Index: 13 Feature: ram\n",
            "Index: 14 Feature: sc_h\n",
            "Index: 19 Feature: wifi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85qeLZBt3Lde"
      },
      "source": [
        "LDA Feature Reduction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kOGpLJB3KRr"
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import eigh\n",
        "# LDA class\n",
        "class LDA:\n",
        "    def __init__(self, n_components=None):\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        classes, cls_counts = np.unique(y, return_counts=True)\n",
        "        priors = cls_counts / n_samples\n",
        "\n",
        "        X_cls_mean = np.array([X[y == cls].mean(axis=0) for cls in classes])\n",
        "        between_cls_deviation = X_cls_mean - X.mean(axis=0)\n",
        "\n",
        "        within_cls_deviation = np.zeros_like(X)\n",
        "        for cls_idx, cls in enumerate(classes):\n",
        "            indices = np.where(y == cls)[0]\n",
        "            within_cls_deviation[indices] = X[indices] - X_cls_mean[cls_idx]\n",
        "\n",
        "        Sb = priors * between_cls_deviation.T @ between_cls_deviation\n",
        "        Sw = within_cls_deviation.T @ within_cls_deviation / n_samples\n",
        "        evals, evecs = eigh(Sb, Sw)\n",
        "        self.dvecs = evecs[:, np.argsort(evals)[::-1]]\n",
        "\n",
        "        self.weights = X_cls_mean @ self.dvecs @ self.dvecs.T\n",
        "        self.bias = np.log(priors) - 0.5 * np.diag(X_cls_mean @ self.weights.T)\n",
        "\n",
        "        if self.n_components is None:\n",
        "            self.n_components = min(classes.size - 1, n_features)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X @ self.dvecs[:, : self.n_components]\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        scores = X_test @ self.weights.T + self.bias\n",
        "        return np.argmax(scores, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy6T8goV3CDk"
      },
      "source": [
        "Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3MlznQ-2__M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class CustomDecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=3):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(np.array(X, dtype=np.float32), np.array(y, dtype=np.int32))\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
        "            return np.bincount(y).argmax()\n",
        "        best_feature, best_threshold = self._find_best_split(X, y)\n",
        "        if best_feature == -1:\n",
        "            return np.bincount(y).argmax()\n",
        "\n",
        "        left_indices = X[:, best_feature] <= best_threshold\n",
        "        right_indices = X[:, best_feature] > best_threshold\n",
        "\n",
        "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "        return (best_feature, best_threshold, left_tree, right_tree)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_feature = -1\n",
        "        best_threshold = -1.0\n",
        "        best_gini = float('inf')\n",
        "        m, n = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        total_class_count = np.bincount(y, minlength=num_classes).astype(np.int64)\n",
        "        left_class_count = np.zeros(num_classes, dtype=np.int64)\n",
        "        right_class_count = total_class_count.copy()\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_indices = np.argsort(X[:, feature])\n",
        "            sorted_X = X[sorted_indices, feature]\n",
        "            sorted_y = y[sorted_indices]\n",
        "\n",
        "            left_class_count[:] = 0\n",
        "            right_class_count[:] = total_class_count\n",
        "            total_left = 0\n",
        "            total_right = m\n",
        "\n",
        "            for i in range(1, m):\n",
        "                c = sorted_y[i - 1]\n",
        "                left_class_count[c] += 1\n",
        "                right_class_count[c] -= 1\n",
        "                total_left += 1\n",
        "                total_right -= 1\n",
        "\n",
        "                if sorted_X[i] == sorted_X[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                gini_left = 1.0 - np.sum((left_class_count / total_left) ** 2)\n",
        "                gini_right = 1.0 - np.sum((right_class_count / total_right) ** 2)\n",
        "                gini = (total_left * gini_left + total_right * gini_right) / m\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = (sorted_X[i] + sorted_X[i - 1]) / 2\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(sample, self.tree) for sample in np.array(X, dtype=np.float32)])\n",
        "\n",
        "    def _predict_sample(self, sample, tree):\n",
        "        if isinstance(tree, tuple):\n",
        "            feature, threshold, left_tree, right_tree = tree\n",
        "            if sample[feature] <= threshold:\n",
        "                return self._predict_sample(sample, left_tree)\n",
        "            else:\n",
        "                return self._predict_sample(sample, right_tree)\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return accuracy_score(np.array(y), self.predict(np.array(X)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTRdLbLk32cN"
      },
      "source": [
        "Apply LDA on the selected features and classify (PSO + LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K2209Wn1Yxa",
        "outputId": "846e7ef2-3c77-49b5-a42d-64be032db2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.86\n"
          ]
        }
      ],
      "source": [
        "# Apply LDA for dimensionality reduction\n",
        "lda = LDA(n_components=6)\n",
        "lda.fit(X_train_selected, y_train)\n",
        "X_train_lda = lda.transform(X_train_selected)\n",
        "X_test_lda = lda.transform(X_test_selected)\n",
        "\n",
        "# Decision Tree classifier with LDA-transformed data\n",
        "model = CustomDecisionTreeClassifier(max_depth=10)\n",
        "model.fit(X_train_lda, y_train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "y_pred_train = model.predict(X_train_lda)\n",
        "\n",
        "# Calculate accuracy\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "# Calculate accuracy on the training data\n",
        "train_accuracy = accuracy(y_train, y_pred_train)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "579mr0z63_Ed"
      },
      "source": [
        "Apply classifier on the selected features directly (PSO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPx5wxSxT2ju",
        "outputId": "40e6e51e-f4c5-4793-c723-d55db669ea37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.98\n"
          ]
        }
      ],
      "source": [
        "# train Decision Tree classifier\n",
        "model = CustomDecisionTreeClassifier(max_depth=10)\n",
        "model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "y_pred_train = model.predict(X_train_selected)\n",
        "\n",
        "# Calculate accuracy\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "# Calculate accuracy on the training data\n",
        "train_accuracy = accuracy(y_train, y_pred_train)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRR7bkPK4JBt"
      },
      "source": [
        "Apply classifier on reducted features directly (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHmT8Ig82fzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0261c9-2239-458e-dd25-0b0bb2891f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.76\n"
          ]
        }
      ],
      "source": [
        "# Apply LDA on the original features\n",
        "lda = LDA(n_components=6)\n",
        "lda.fit(X_train.values, y_train_mapped)\n",
        "X_train_lda_original = lda.transform(X_train.values)\n",
        "\n",
        "# Initialize and train the custom Decision Tree classifier\n",
        "model = CustomDecisionTreeClassifier(max_depth=10)\n",
        "model.fit(X_train_lda_original, y_train_mapped)\n",
        "\n",
        "# Make predictions on the training data\n",
        "y_pred_train = model.predict(X_train_lda_original)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy(y_train_mapped, y_pred_train)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on test data"
      ],
      "metadata": {
        "id": "_3sr-nJpDD_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature selection and LDA transformation to the test data\n",
        "X_test_selected = X_test[selected_features_train].values.astype(float)\n",
        "X_test_lda = lda.transform(X_test.values)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_test = model.predict(X_test_lda)\n",
        "\n",
        "print(\"Model Predictions on Test Data:\")\n",
        "print(y_pred_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zxRkfXsDDUN",
        "outputId": "b5f84861-dd24-4c4d-c2fd-fc085adf1083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Predictions on Test Data:\n",
            "[0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0\n",
            " 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0\n",
            " 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0\n",
            " 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
            " 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 0\n",
            " 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1\n",
            " 1 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0\n",
            " 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0\n",
            " 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1\n",
            " 0 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1\n",
            " 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1\n",
            " 1]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5036255,
          "sourceId": 8450890,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}